We are going to simulate something that we can see in betting webpages. 
Imagine the final match of the European Championship, which is viewed by millions of people across the continent. 
Now imagine that we own a betting webpage, where we provide historical information about every team in Europe. 
This is plenty of information, which is usually stored in some distributed database, and each team has, literally, 
megabytes of information about their players, matches, championships, and so on

If a million users access information about a team and a new instance of the information is created for each user querying for 
historical data, we will run out of memory in the blink of an eye. With our Proxy solution, we could make a cache of the most recent 
searches to speed up queries, but if we return a clone for every team, we will still get short on memory (but faster thanks to our cache). 
Funny, right?

Instead, we will store each team's information just once, and we will deliver references to them to the users. 
So, if we face a million users trying to access information about a match, we will actually just have two teams in memory with a million 
pointers to the same memory direction.

ACCEPTANCE CRITERIA:
    1. We will create a Team struct with some basic information.
    2. We must ensure correct team creation and not having any duplicates.
    3. When creating the same team twice we need to have two pointers pointing towards the same location